import fetch from 'cross-fetch';
import FormData from 'form-data';
import { z } from 'zod';

function _defineProperty(obj, key, value) {
  if (key in obj) {
    Object.defineProperty(obj, key, {
      value: value,
      enumerable: true,
      configurable: true,
      writable: true
    });
  } else {
    obj[key] = value;
  }

  return obj;
}

/**
 * @internal
 */
const DEFAULT_IPFS_GATEWAY = "https://gateway.ipfscdn.io/ipfs/";
/**
 * @internal
 */

const PUBLIC_GATEWAYS = ["https://gateway.ipfscdn.io/ipfs/", "https://cloudflare-ipfs.com/ipfs/", "https://ipfs.io/ipfs/"];
/**
 * @internal
 */

const TW_IPFS_SERVER_URL = "https://upload.nftlabs.co";
/**
 * @internal
 */

const PINATA_IPFS_URL = "https://api.pinata.cloud/pinning/pinFileToIPFS";

function isFileInstance(data) {
  return global.File && data instanceof File;
}
function isBufferInstance(data) {
  return global.Buffer && data instanceof Buffer;
}
/**
 * Given a map of file hashes to ipfs uris, this function will hash
 * all properties recursively and replace them with the ipfs uris
 * from the map passed in. If a hash is missing from the map, the function
 * will throw an error.
 *
 * @internal
 *
 * @param object - The object to recursively process
 * @param cids - The array of file hashes to ipfs uris in the recurse order
 * @returns - The processed metadata with properties pointing at ipfs in place of `File | Buffer`
 */

function replaceFilePropertiesWithHashes(object, cids, scheme) {
  const keys = Object.keys(object);

  for (const key in keys) {
    const val = object[keys[key]];
    const isFile = isFileInstance(val) || isBufferInstance(val);

    if (typeof val === "object" && !isFile) {
      replaceFilePropertiesWithHashes(val, cids, scheme);
      continue;
    }

    if (!isFile) {
      continue;
    }

    object[keys[key]] = "".concat(scheme).concat(cids.splice(0, 1)[0]);
  }

  return object;
}
/**
 * Replaces all ipfs:// hashes (or any other scheme) with gateway url
 * @internal
 * @param object
 * @param scheme
 * @param gatewayUrl
 */

function replaceHashWithGatewayUrl(object, scheme, gatewayUrl) {
  if (object === null || !object) {
    return {};
  }

  const keys = Object.keys(object);

  for (const key in keys) {
    const val = object[keys[key]];
    object[keys[key]] = resolveGatewayUrl(val, scheme, gatewayUrl);

    if (Array.isArray(val)) {
      object[keys[key]] = val.map(el => {
        if (typeof el === "object") {
          return replaceHashWithGatewayUrl(el, scheme, gatewayUrl);
        } else {
          return resolveGatewayUrl(el, scheme, gatewayUrl);
        }
      });
    }

    if (typeof val === "object") {
      replaceHashWithGatewayUrl(val, scheme, gatewayUrl);
    }
  }

  return object;
}
/**
 * Replaces all gateway urls back to ipfs:// hashes
 * @internal
 * @param object
 * @param scheme
 * @param gatewayUrl
 */

function replaceGatewayUrlWithHash(object, scheme, gatewayUrl) {
  if (object === null || !object) {
    return {};
  }

  const keys = Object.keys(object);

  for (const key in keys) {
    const val = object[keys[key]];
    object[keys[key]] = toIPFSHash(val, scheme, gatewayUrl);

    if (Array.isArray(val)) {
      object[keys[key]] = val.map(el => {
        const isFile = isFileInstance(el) || isBufferInstance(el);

        if (typeof el === "object" && !isFile) {
          return replaceGatewayUrlWithHash(el, scheme, gatewayUrl);
        } else {
          return toIPFSHash(el, scheme, gatewayUrl);
        }
      });
    }

    const isFile = isFileInstance(val) || isBufferInstance(val);

    if (typeof val === "object" && !isFile) {
      replaceGatewayUrlWithHash(val, scheme, gatewayUrl);
    }
  }

  return object;
}
/**
 * Resolves the full URL of a file for a given gateway.
 *
 * For example, if the hash of a file is `ipfs://bafkreib3u2u6ir2fsl5nkuwixfsb3l4xehri3psjv5yga4inuzsjunk2sy`, then the URL will be:
 * "https://cloudflare-ipfs.com/ipfs/bafkreibnwjhx5s3r2rggdoy3hw7lr7wmgy4bas35oky3ed6eijklk2oyvq"
 * if the gateway is `cloudflare-ipfs.com`.
 * @internal
 * @param object
 * @param scheme
 * @param gatewayUrl
 */

function resolveGatewayUrl(object, scheme, gatewayUrl) {
  if (typeof object === "string") {
    return object && object.toLowerCase().includes(scheme) ? object.replace(scheme, gatewayUrl) : object;
  } else {
    return object;
  }
}
/**
 * @internal
 * @param object
 * @param scheme
 * @param gatewayUrl
 */

function toIPFSHash(object, scheme, gatewayUrl) {
  if (typeof object === "string") {
    return object && object.toLowerCase().includes(gatewayUrl) ? object.replace(gatewayUrl, scheme) : object;
  } else {
    return object;
  }
}

/**
 * @internal
 */

class PinataUploader {
  /**
   * Fetches a one-time-use upload token that can used to upload
   * a file to storage.
   *
   * @returns - The one time use token that can be passed to the Pinata API.
   */
  async getUploadToken(contractAddress) {
    const headers = {
      "X-App-Name": "CONSOLE-TS-SDK-".concat(contractAddress)
    };
    const res = await fetch("".concat(TW_IPFS_SERVER_URL, "/grant"), {
      method: "GET",
      headers
    });

    if (!res.ok) {
      throw new Error("Failed to get upload token");
    }

    const body = await res.text();
    return body;
  }

  async uploadBatchWithCid(files) {
    let fileStartNumber = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
    let contractAddress = arguments.length > 2 ? arguments[2] : undefined;
    let signerAddress = arguments.length > 3 ? arguments[3] : undefined;
    let options = arguments.length > 4 ? arguments[4] : undefined;
    const token = await this.getUploadToken(contractAddress || "");
    const formData = new FormData();
    const {
      data,
      fileNames
    } = this.buildFormData(formData, files, fileStartNumber, contractAddress, signerAddress);

    if (typeof window === "undefined") {
      if (options !== null && options !== void 0 && options.onProgress) {
        console.warn("The onProgress option is only supported in the browser");
      }

      const res = await fetch(PINATA_IPFS_URL, {
        method: "POST",
        headers: {
          Authorization: "Bearer ".concat(token),
          ...data.getHeaders()
        },
        body: data.getBuffer()
      });
      const body = await res.json();

      if (!res.ok) {
        throw new Error("Failed to upload files to IPFS");
      }

      const cid = body.IpfsHash;

      if (!cid) {
        throw new Error("Failed to upload files to IPFS");
      }

      return {
        cid,
        fileNames
      };
    } else {
      return new Promise((resolve, reject) => {
        const xhr = new XMLHttpRequest();
        xhr.open("POST", PINATA_IPFS_URL);
        xhr.setRequestHeader("Authorization", "Bearer ".concat(token));

        xhr.onloadend = () => {
          if (xhr.status !== 200) {
            throw new Error("Failed to upload files to IPFS");
          }

          const cid = JSON.parse(xhr.responseText).IpfsHash;

          if (!cid) {
            throw new Error("Failed to upload files to IPFS");
          }

          resolve({
            cid,
            fileNames
          });
        };

        xhr.onerror = err => {
          reject(err);
        };

        if (xhr.upload) {
          xhr.upload.onprogress = event => {
            if (options !== null && options !== void 0 && options.onProgress) {
              options === null || options === void 0 ? void 0 : options.onProgress({
                progress: event.loaded,
                total: event.total
              });
            }
          };
        }

        xhr.send(data);
      });
    }
  }

  buildFormData(data, files) {
    let fileStartNumber = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
    let contractAddress = arguments.length > 3 ? arguments[3] : undefined;
    let signerAddress = arguments.length > 4 ? arguments[4] : undefined;
    const metadata = {
      name: "CONSOLE-TS-SDK-".concat(contractAddress),
      keyvalues: {
        sdk: "typescript",
        contractAddress,
        signerAddress
      }
    };
    const fileNames = [];
    files.forEach((file, i) => {
      let fileName = "";
      let fileData = file; // if it is a file, we passthrough the file extensions,
      // if it is a buffer or string, the filename would be fileStartNumber + index
      // if it is a buffer or string with names, the filename would be the name

      if (isFileInstance(file)) {
        let extensions = "";

        if (file.name) {
          const extensionStartIndex = file.name.lastIndexOf(".");

          if (extensionStartIndex > -1) {
            extensions = file.name.substring(extensionStartIndex);
          }
        }

        fileName = "".concat(i + fileStartNumber).concat(extensions);
      } else if (isBufferInstance(file) || typeof file === "string") {
        fileName = "".concat(i + fileStartNumber);
      } else if (file && file.name && file !== null && file !== void 0 && file.data) {
        fileData = file === null || file === void 0 ? void 0 : file.data;
        fileName = "".concat(file.name);
      } else {
        // default behavior
        fileName = "".concat(i + fileStartNumber);
      }

      const filepath = "files/".concat(fileName);

      if (fileNames.indexOf(fileName) > -1) {
        throw new Error("DUPLICATE_FILE_NAME_ERROR: File name ".concat(fileName, " was passed for more than one file."));
      }

      fileNames.push(fileName);

      if (typeof window === "undefined") {
        data.append("file", fileData, {
          filepath
        });
      } else {
        // browser does blob things, filepath is parsed differently on browser vs node.
        // pls pinata?
        data.append("file", new Blob([fileData]), filepath);
      }
    });
    data.append("pinataMetadata", JSON.stringify(metadata));
    return {
      data,
      fileNames
    };
  }

}

/**
 * IPFS Storage implementation, accepts custom IPFS gateways
 * @remarks By default, thirdweb automatically uploads files to IPFS when you perform operations such as minting, this class allows you to do it manually.
 * @public
 */

class IpfsStorage {
  /**
   * {@inheritdoc IStorage.gatewayUrl}
   * @internal
   */
  constructor() {
    let gatewayUrl = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : DEFAULT_IPFS_GATEWAY;
    let uploader = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new PinataUploader();
    let options = arguments.length > 2 ? arguments[2] : undefined;

    _defineProperty(this, "gatewayUrl", void 0);

    _defineProperty(this, "failedUrls", []);

    _defineProperty(this, "uploader", void 0);

    _defineProperty(this, "options", void 0);

    this.gatewayUrl = "".concat(gatewayUrl.replace(/\/$/, ""), "/");
    this.uploader = uploader;
    this.options = options;
  }

  getNextPublicGateway() {
    const urlsToTry = PUBLIC_GATEWAYS.filter(url => !this.failedUrls.includes(url)).filter(url => url !== this.gatewayUrl);

    if (urlsToTry.length > 0) {
      return urlsToTry[0];
    } else {
      this.failedUrls = [];
      return undefined;
    }
  }

  getBaseUri() {
    var _this$options;

    if ((_this$options = this.options) !== null && _this$options !== void 0 && _this$options.appendGatewayUrl) {
      return this.gatewayUrl;
    } else {
      return "ipfs://";
    }
  }
  /**
   * Upload a file to IPFS and return the hash
   * @remarks This method is a wrapper around {@link IStorage.upload}
   * @example
   * ```javascript
   * const file = './path/to/file.png'; // Can be a path or a File object such as a file from an input element.
   * const hash = await sdk.storage.upload(file);
   * ```
   *
   *
   */


  async upload(data, contractAddress, signerAddress, options) {
    const {
      cid,
      fileNames
    } = await this.uploader.uploadBatchWithCid([data], 0, contractAddress, signerAddress, options);
    const baseUri = "".concat(this.getBaseUri()).concat(cid, "/");
    return "".concat(baseUri).concat(fileNames[0]);
  }
  /**
   * {@inheritDoc IStorage.uploadBatch}
   */


  async uploadBatch(files) {
    let fileStartNumber = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
    let contractAddress = arguments.length > 2 ? arguments[2] : undefined;
    let signerAddress = arguments.length > 3 ? arguments[3] : undefined;
    let options = arguments.length > 4 ? arguments[4] : undefined;
    const {
      cid,
      fileNames
    } = await this.uploader.uploadBatchWithCid(files, fileStartNumber, contractAddress, signerAddress, options);
    const baseUri = "".concat(this.getBaseUri()).concat(cid, "/");
    const uris = fileNames.map(filename => "".concat(baseUri).concat(filename));
    return {
      baseUri,
      uris
    };
  }
  /**
   * {@inheritDoc IStorage.get}
   */


  async get(hash) {
    const res = await this._get(hash);
    const json = await res.json();
    return replaceHashWithGatewayUrl(json, "ipfs://", this.gatewayUrl);
  }
  /**
   * {@inheritDoc IStorage.getRaw}
   */


  async getRaw(hash) {
    const res = await this._get(hash);
    return await res.text();
  }
  /**
   * {@inheritDoc IStorage.uploadMetadata}
   */


  async uploadMetadata(metadata, contractAddress, signerAddress, options) {
    // since there's only single object, always use the first index
    const {
      uris
    } = await this.uploadMetadataBatch([metadata], 0, contractAddress, signerAddress, options);
    return uris[0];
  }
  /**
   * {@inheritDoc IStorage.uploadMetadataBatch}
   */


  async uploadMetadataBatch(metadatas, fileStartNumber, contractAddress, signerAddress, options) {
    const metadataToUpload = (await this.batchUploadProperties(metadatas, options)).map(m => JSON.stringify(m));
    const {
      cid,
      fileNames
    } = await this.uploader.uploadBatchWithCid(metadataToUpload, fileStartNumber, contractAddress, signerAddress);
    const baseUri = "".concat(this.getBaseUri()).concat(cid, "/");
    const uris = fileNames.map(filename => "".concat(baseUri).concat(filename));
    return {
      baseUri,
      uris
    };
  }
  /** *************************
   * PRIVATE FUNCTIONS
   *************************/


  async _get(hash) {
    let uri = hash;

    if (hash) {
      uri = resolveGatewayUrl(hash, "ipfs://", this.gatewayUrl);
    }

    const result = await fetch(uri);

    if (!result.ok && result.status === 500) {
      throw new Error("Error fetching ".concat(uri, " - Status code ").concat(result.status));
    }

    if (!result.ok && result.status !== 404) {
      const nextUrl = this.getNextPublicGateway();

      if (nextUrl) {
        this.failedUrls.push(this.gatewayUrl);
        this.gatewayUrl = nextUrl;
        return this._get(hash);
      } else {
        throw new Error("Error fetching ".concat(uri, " - Status code ").concat(result.status));
      }
    }

    return result;
  }
  /**
   * Pre-processes metadata and uploads all file properties
   * to storage in *bulk*, then performs a string replacement of
   * all file properties -\> the resulting ipfs uri. This is
   * called internally by `uploadMetadataBatch`.
   *
   * @internal
   *
   * @returns - The processed metadata with properties pointing at ipfs in place of `File | Buffer`
   * @param metadatas
   * @param options
   */


  async batchUploadProperties(metadatas, options) {
    // replace all active gateway url links with their raw ipfs hash
    const sanitizedMetadatas = replaceGatewayUrlWithHash(metadatas, this.getBaseUri(), this.gatewayUrl); // extract any binary file to upload

    const filesToUpload = sanitizedMetadatas.flatMap(m => this.buildFilePropertiesMap(m, [])); // if no binary files to upload, return the metadata

    if (filesToUpload.length === 0) {
      return sanitizedMetadatas;
    } // otherwise upload those files


    const {
      cid,
      fileNames
    } = await this.uploader.uploadBatchWithCid(filesToUpload, undefined, undefined, undefined, options);
    const cids = []; // recurse ordered array

    for (const filename of fileNames) {
      cids.push("".concat(cid, "/").concat(filename));
    } // replace all files with their ipfs hash


    return replaceFilePropertiesWithHashes(sanitizedMetadatas, cids, this.getBaseUri());
  }
  /**
   * This function recurisely traverses an object and hashes any
   * `Buffer` or `File` objects into the returned map.
   *
   * @param object - the Json Object
   * @param files - The running array of files or buffer to upload
   * @returns - The final map of all hashes to files
   */


  buildFilePropertiesMap(object) {
    let files = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];

    if (Array.isArray(object)) {
      object.forEach(element => {
        this.buildFilePropertiesMap(element, files);
      });
    } else if (object) {
      const values = Object.values(object);

      for (const val of values) {
        if (isFileInstance(val) || isBufferInstance(val)) {
          files.push(val);
        } else if (typeof val === "object") {
          this.buildFilePropertiesMap(val, files);
        }
      }
    }

    return files;
  }
  /**
   * FOR TESTING ONLY
   * @internal
   * @param data -
   * @param contractAddress -
   * @param signerAddress -
   */


  async uploadSingle(data, contractAddress, signerAddress) {
    // TODO move down to IStorageUpload
    const token = await this.uploader.getUploadToken(contractAddress || "");
    const metadata = {
      name: "CONSOLE-TS-SDK-".concat(contractAddress),
      keyvalues: {
        sdk: "typescript",
        contractAddress,
        signerAddress
      }
    };
    const formData = new FormData();
    const filepath = "files"; // Root directory

    formData.append("file", data, filepath);
    formData.append("pinataMetadata", JSON.stringify(metadata));
    formData.append("pinataOptions", JSON.stringify({
      wrapWithDirectory: false
    }));
    const res = await fetch(PINATA_IPFS_URL, {
      method: "POST",
      headers: {
        Authorization: "Bearer ".concat(token),
        ...formData.getHeaders()
      },
      body: formData.getBuffer()
    });

    if (!res.ok) {
      throw new Error("Failed to upload to IPFS [status code = ".concat(res.status, "]"));
    }

    const body = await res.json();
    return body.IpfsHash;
  }

}

/**
 * Fetch and upload files to IPFS or any other storage.
 * @public
 */
class RemoteStorage {
  constructor(storage) {
    _defineProperty(this, "storage", void 0);

    this.storage = storage;
  }
  /**
   * Fetch data from any IPFS hash without worrying about gateways, data types, etc.
   * Simply pass in an IPFS url and we'll handle fetching for you and try every public gateway
   * to get the fastest response.
   *
   * @example
   * ```javascript
   * // Your IPFS hash here
   * const hash = "ipfs://..."
   * const data = await sdk.storage.fetch(hash);
   * ```
   * @param hash - The IPFS hash of the file or data to fetch
   * @returns The data stored at the specified IPFS hash
   */


  async fetch(hash) {
    return this.storage.get(hash);
  }
  /**
   * Upload any data to an IPFS directory. We'll handle all the details for you, including
   * pinning your files and making sure that you get the fastest upload speeds.
   *
   * @example
   * ```javascript
   * // File upload
   * const files = [
   *   fs.readFileSync("file1.png"),
   *   fs.readFileSync("file2.png"),
   * ]
   * const result = await sdk.storage.upload(files);
   * // uri for each uploaded file will look like something like: ipfs://<hash>/0
   *
   * // JSON metadata upload
   * const jsonMetadata = {
   *   name: "Name",
   *   description: "Description",
   * }
   * const result = await sdk.storage.upload(jsonMetadata);
   *
   * // Upload progress (browser only)
   * const result = await sdk.storage.upload(files, {
   *   onProgress: (event: UploadProgressEvent) => {
   *     console.log(`Downloaded ${event.progress} / ${event.total}`);
   *   },
   * });
   * ```
   *
   * @param data - An array of file data or an array of JSON metadata to upload to IPFS
   * @param options - Optional. Upload progress callback.
   * @returns The IPFS hash of the directory that holds all the uploaded data
   */


  async upload(data, options) {
    if (!Array.isArray(data)) {
      if (isFileInstance(data) || isBufferInstance(data) || data.name && data.data && isBufferInstance(data.data)) {
        return this.uploadBatch([data], options);
      } else {
        return this.uploadMetadataBatch([data], options);
      }
    }

    const allFiles = data.filter(item => isFileInstance(item) || isBufferInstance(item) || item.name && item.data && isBufferInstance(item.data));
    const allObjects = data.filter(item => !isFileInstance(item) && !isBufferInstance(item));

    if (allFiles.length === data.length) {
      return this.uploadBatch(data, options);
    } else if (allObjects.length === data.length) {
      return this.uploadMetadataBatch(data, options);
    } else {
      throw new Error("Data to upload must be either all files or all JSON objects");
    }
  }

  async uploadBatch(files, options) {
    return await this.storage.uploadBatch(files, undefined, undefined, undefined, options);
  }

  async uploadMetadataBatch(metadatas, options) {
    return await this.storage.uploadMetadataBatch(metadatas, undefined, undefined, undefined, options);
  }

}

const isBrowser = () => typeof window !== "undefined";
const fileOrBufferUnion = isBrowser() ? [z.instanceof(File), z.string()] : [z.instanceof(Buffer), z.string()];
const FileBufferOrStringSchema = z.union(fileOrBufferUnion);

export { FileBufferOrStringSchema, IpfsStorage, PinataUploader, RemoteStorage, isBrowser, isBufferInstance, isFileInstance };
